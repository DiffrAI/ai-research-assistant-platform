# =============================================================================
# AI RESEARCH ASSISTANT PLATFORM - ENVIRONMENT CONFIGURATION
# =============================================================================
# Copy this file to .env and update the values as needed
# Never commit your actual .env file to version control

# =============================================================================
# CORE APPLICATION SETTINGS
# =============================================================================
ENVIRONMENT=development         # Options: development | qa | demo | production
LOG_LEVEL=DEBUG                # Options: TRACE | DEBUG | INFO | WARNING | ERROR
RELEASE_VERSION=0.0.1

# Server Configuration
HOST=0.0.0.0
PORT=8002
WORKER_COUNT=4                 # Auto-detected if not set
DEBUG=true

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================
# SQLite (Development) - Recommended for local development
DATABASE_URL=sqlite+aiosqlite:///./ai_research.db

# PostgreSQL (Production) - Uncomment and configure for production
# DATABASE_URL=postgresql+asyncpg://user:password@localhost:5432/ai_research

# =============================================================================
# SECURITY & AUTHENTICATION
# =============================================================================
# IMPORTANT: Change this in production!
SECRET_KEY=your-secret-key-change-in-production
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
REFRESH_TOKEN_EXPIRE_DAYS=7

# =============================================================================
# AI MODEL CONFIGURATION
# =============================================================================
# Local Model (Ollama) - Recommended for development (FREE)
USE_LOCAL_MODEL=true
LOCAL_MODEL_URL=http://127.0.0.1:11434
LOCAL_MODEL_NAME=qwen2.5:7b    # Must match the model loaded in Ollama

# OpenAI (Alternative to local model) - PAID
# USE_LOCAL_MODEL=false
# OPENAI_API_KEY=your_openai_api_key_here

# =============================================================================
# WEB SEARCH CONFIGURATION
# =============================================================================
# Search Provider (DuckDuckGo is free, Tavily is paid)
SEARCH_PROVIDER=duckduckgo      # Options: duckduckgo | tavily
DUCKDUCKGO_MAX_RESULTS=10
SEARCH_MAX_RETRIES=3           # Number of retries for web search
SEARCH_BASE_DELAY=1.0          # Base delay (seconds) for exponential backoff
SEARCH_MAX_DELAY=10.0          # Max delay (seconds) for exponential backoff

# Tavily (Alternative to DuckDuckGo) - PAID
# TAVILY_API_KEY=your_tavily_api_key_here

# =============================================================================
# CACHE & RATE LIMITING
# =============================================================================
# Cache Backend (local for dev, redis for production)
CACHE_BACKEND=local            # Options: local | redis
RATE_LIMIT_BACKEND=local       # Options: local | redis

# Redis Configuration (for cache and rate limiting)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=your_redis_password

# =============================================================================
# PAYMENT & SUBSCRIPTION (Stripe)
# =============================================================================
# Get these from your Stripe dashboard: https://dashboard.stripe.com/apikeys
STRIPE_SECRET_KEY=sk_test_your_stripe_secret_key
STRIPE_PUBLISHABLE_KEY=pk_test_your_stripe_publishable_key
STRIPE_WEBHOOK_SECRET=whsec_your_webhook_secret

# =============================================================================
# MONITORING & OBSERVABILITY (Optional)
# =============================================================================
# LangFuse (Optional - for LLM observability)
# Get these from: https://cloud.langfuse.com
# LANGFUSE_HOST=https://cloud.langfuse.com
# LANGFUSE_PUBLIC_KEY=your_langfuse_public_key
# LANGFUSE_SECRET_KEY=your_langfuse_secret_key

# Grafana (Optional - for metrics)
GF_SECURITY_ADMIN_USER=admin
GF_SECURITY_ADMIN_PASSWORD=supersecurepassword

# =============================================================================
# DEVELOPMENT NOTES
# =============================================================================
# 
# 1. For local development, you only need:
#    - SECRET_KEY (any string)
#    - USE_LOCAL_MODEL=true
#    - LOCAL_MODEL_NAME (must match your Ollama model)
#    - SEARCH_PROVIDER=duckduckgo
#
# 2. To use Ollama:
#    - Install Ollama: https://ollama.ai
#    - Pull a model: ollama pull qwen2.5:7b
#    - Start Ollama: ollama serve
#
# 3. For production, you'll need:
#    - A strong SECRET_KEY
#    - Stripe API keys
#    - Redis (for caching and rate limiting)
#    - PostgreSQL (instead of SQLite)
#
# 4. Optional but recommended:
#    - LangFuse for LLM observability
#    - Grafana for metrics monitoring 