# Core Settings
LOG_LEVEL=DEBUG
ENVIRONMENT=development
HOST=0.0.0.0
PORT=8002

# Model Configuration - Use Ollama (Recommended)
USE_LOCAL_MODEL=true
LOCAL_MODEL_URL=http://127.0.0.1:11434  # Ollama default endpoint
LOCAL_MODEL_NAME=qwen2.5:7b             # Must match the model loaded in Ollama

# Search Provider Configuration - Use DuckDuckGo (Free)
SEARCH_PROVIDER=duckduckgo
DUCKDUCKGO_MAX_RESULTS=10
SEARCH_MAX_RETRIES=3         # Number of retries for DuckDuckGo search
SEARCH_BASE_DELAY=1.0        # Base delay (seconds) for exponential backoff
SEARCH_MAX_DELAY=10.0        # Max delay (seconds) for exponential backoff

# Optional: OpenAI Configuration (used when USE_LOCAL_MODEL=false)
# OPENAI_API_KEY=your_openai_api_key_here

# Optional: Tavily Configuration (used when SEARCH_PROVIDER=tavily)
# TAVILY_API_KEY=your_tavily_api_key_here

# Optional: Langfuse (Observability)
# LANGFUSE_HOST=https://cloud.langfuse.com
# LANGFUSE_PUBLIC_KEY=your_langfuse_public_key
# LANGFUSE_SECRET_KEY=your_langfuse_secret_key

# Redis (Caching & Rate Limiting) - Optional for development
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=your_redis_password

# Monitoring - Optional
GF_SECURITY_ADMIN_USER=admin
GF_SECURITY_ADMIN_PASSWORD=admin 